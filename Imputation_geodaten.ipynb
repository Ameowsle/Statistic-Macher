{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde88714",
   "metadata": {},
   "source": [
    "# Imputation der Geo-Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3efe872",
   "metadata": {},
   "source": [
    "## 1. Datenvorbereitung und Bereinigung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e48e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from pyproj import Transformer\n",
    "from geopy.geocoders import Nominatim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "pd.set_option('display.max_info_columns', 10000)   # zeigt alle Spaltennamen in info()\n",
    "pd.set_option('display.max_info_rows', 200000)     # zeigt Zeileninfo, wenn nötig\n",
    "\n",
    "\n",
    "# Pfad zur Datei \n",
    "path = Path(\"dataset/311_Service_Requests_2024.csv\")\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db54100",
   "metadata": {},
   "source": [
    "## 2. Einteilung der Spalten mit Geodaten und Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte in Geodaten-Spalten:\n",
      "                  Anzahl fehlender Werte  Prozent fehlender Werte\n",
      "ZIP_CODE                          210954                11.022039\n",
      "CITY                              152869                 7.987182\n",
      "STATE                             152869                 7.987182\n",
      "STREET_TYPE                        17446                 0.911528\n",
      "COMMUNITY_AREA                      1809                 0.094518\n",
      "WARD                                1741                 0.090965\n",
      "POLICE_DISTRICT                     1677                 0.087621\n",
      "LATITUDE                            1062                 0.055488\n",
      "LONGITUDE                           1062                 0.055488\n",
      "LOCATION                            1062                 0.055488\n",
      "Y_COORDINATE                        1015                 0.053032\n",
      "X_COORDINATE                        1015                 0.053032\n",
      "STREET_DIRECTION                     934                 0.048800\n",
      "STREET_NUMBER                        835                 0.043628\n",
      "STREET_ADDRESS                       806                 0.042112\n",
      "STREET_NAME                          806                 0.042112\n"
     ]
    }
   ],
   "source": [
    "# Nur Geodaten-Spalten analysieren\n",
    "geo_cols = ['STREET_ADDRESS','STREET_NUMBER', 'STREET_NAME', 'STREET_DIRECTION', 'STREET_TYPE','CITY',\n",
    "            'STATE', 'ZIP_CODE', 'LATITUDE', 'LONGITUDE', 'X_COORDINATE', 'Y_COORDINATE', 'LOCATION',]\n",
    "\n",
    "missing_count = df[geo_cols].isnull().sum()\n",
    "missing_percent = df[geo_cols].isnull().mean() * 100\n",
    "\n",
    "# Erstellung DataFrames für Übersicht\n",
    "missing_df = pd.DataFrame({\n",
    "    'Anzahl fehlender Werte': missing_count,\n",
    "    'Prozent fehlender Werte': missing_percent\n",
    "})\n",
    "\n",
    "# Sortierung nach Anzahl fehlender Werte (absteigend)\n",
    "missing_df = missing_df[missing_df['Anzahl fehlender Werte'] > 0]\n",
    "missing_df = missing_df.sort_values(by='Anzahl fehlender Werte', ascending=False)\n",
    "\n",
    "print(\"Fehlende Werte in Geodaten-Spalten:\")\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baada54",
   "metadata": {},
   "source": [
    "Wir sehen, dass ca. 1000 Geo-Daten fehlen, also wo die SR aufgenommen wurden. Wir versuchen jetzt aus den gegebenen Spalten (z B STREET_ADDRESS) andere Spalten (z B LATITUDE) herauszubekommen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03deeb36",
   "metadata": {},
   "source": [
    "## 3. Funktion für die Imputation der Koordinaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_missing_addresses(df):\n",
    "    geolocator = Nominatim(user_agent=\"chicago_311_geocoder_12345\")\n",
    "    \n",
    "    missing = df['LATITUDE'].isna() & df['STREET_ADDRESS'].notna()\n",
    "    to_geocode = df[missing].copy()\n",
    "    \n",
    "    total = len(to_geocode)\n",
    "    print(f\"Geocodiere {total} Adressen (ca. {total // 60 + 1} Minuten)\\n\")\n",
    "    \n",
    "    results = []\n",
    "    success = 0\n",
    "    \n",
    "    for i, (idx, row) in enumerate(to_geocode.iterrows(), 1):\n",
    "        try:\n",
    "            address = f\"{row['STREET_ADDRESS']}, Chicago, IL, USA\"\n",
    "            location = geolocator.geocode(address, timeout=10)\n",
    "            \n",
    "            if location:\n",
    "                results.append({\n",
    "                    'index': idx,\n",
    "                    'latitude': location.latitude,\n",
    "                    'longitude': location.longitude\n",
    "                })\n",
    "                success += 1\n",
    "                \n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        if i % 50 == 0 or i == total:\n",
    "            print(f\"{i}/{total} ({i/total*100:.1f}%) - Gefunden: {success}\")\n",
    "\n",
    "    # Koordinaten in DF schreiben\n",
    "    for result in results:\n",
    "        df.loc[result['index'], 'LATITUDE'] = result['latitude']\n",
    "        df.loc[result['index'], 'LONGITUDE'] = result['longitude']\n",
    "        df.loc[result['index'], 'LOCATION'] = f\"({result['latitude']}, {result['longitude']})\"\n",
    "    \n",
    "    print(f\"\\nErfolgreich: {success}/{total} ({success/total*100:.1f}%)\")\n",
    "    \n",
    "    # Rückgabe zusätzlich: Liste der neuen Indizes\n",
    "    new_indices = [r['index'] for r in results]\n",
    "    return df, new_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4226672",
   "metadata": {},
   "source": [
    "## 4. Funktion zum Hinzufügen der gefundenen Missing Values und zum Berechnen der Lat/Long aus X/Y und umgekehrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d54acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_coordinates(df):\n",
    "    print(\"\\nCODE 2: Koordinaten-Imputation gestartet\\n\")\n",
    "    \n",
    "    missing_address = df['STREET_ADDRESS'].isna()\n",
    "    has_components = df['STREET_NUMBER'].notna() & df['STREET_NAME'].notna()\n",
    "    to_reconstruct = missing_address & has_components\n",
    "    \n",
    "    if to_reconstruct.sum() > 0:\n",
    "        print(f\"Rekonstruiere {to_reconstruct.sum()} Adressen...\")\n",
    "        for idx in df[to_reconstruct].index:\n",
    "            parts = []\n",
    "            if pd.notna(df.loc[idx, 'STREET_NUMBER']):\n",
    "                parts.append(str(int(df.loc[idx, 'STREET_NUMBER'])))\n",
    "            if pd.notna(df.loc[idx, 'STREET_DIRECTION']):\n",
    "                parts.append(df.loc[idx, 'STREET_DIRECTION'])\n",
    "            if pd.notna(df.loc[idx, 'STREET_NAME']):\n",
    "                parts.append(df.loc[idx, 'STREET_NAME'])\n",
    "            if pd.notna(df.loc[idx, 'STREET_TYPE']):\n",
    "                parts.append(df.loc[idx, 'STREET_TYPE'])\n",
    "            \n",
    "            if parts:\n",
    "                df.loc[idx, 'STREET_ADDRESS'] = ' '.join(parts)\n",
    "    \n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3435\", always_xy=True)\n",
    "    missing_xy = df['X_COORDINATE'].isna() & df['LATITUDE'].notna()\n",
    "\n",
    "    if missing_xy.sum() > 0:\n",
    "        for idx in df[missing_xy].index:\n",
    "            lat = df.loc[idx, 'LATITUDE']\n",
    "            lon = df.loc[idx, 'LONGITUDE']\n",
    "            if pd.notna(lat) and pd.notna(lon):\n",
    "                x, y = transformer.transform(lon, lat)\n",
    "                df.loc[idx, 'X_COORDINATE'] = x\n",
    "                df.loc[idx, 'Y_COORDINATE'] = y\n",
    "    \n",
    "    transformer_reverse = Transformer.from_crs(\"EPSG:3435\", \"EPSG:4326\", always_xy=True)\n",
    "    missing_latlon = df['LATITUDE'].isna() & df['X_COORDINATE'].notna()\n",
    "\n",
    "    if missing_latlon.sum() > 0:\n",
    "        for idx in df[missing_latlon].index:\n",
    "            x = df.loc[idx, 'X_COORDINATE']\n",
    "            y = df.loc[idx, 'Y_COORDINATE']\n",
    "            if pd.notna(x) and pd.notna(y):\n",
    "                lon, lat = transformer_reverse.transform(x, y)\n",
    "                df.loc[idx, 'LATITUDE'] = lat\n",
    "                df.loc[idx, 'LONGITUDE'] = lon\n",
    "    \n",
    "    missing_location = df['LOCATION'].isna() & df['LATITUDE'].notna()\n",
    "    if missing_location.sum() > 0:\n",
    "        df.loc[missing_location, 'LOCATION'] = df[missing_location].apply(\n",
    "            lambda row: f\"({row['LATITUDE']}, {row['LONGITUDE']})\", axis=1\n",
    "        )\n",
    "\n",
    "    has_geo = df['STREET_ADDRESS'].notna() | df['LATITUDE'].notna() | df['WARD'].notna()\n",
    "    missing_city = df['CITY'].isna() & has_geo\n",
    "    missing_state = df['STATE'].isna() & has_geo\n",
    "\n",
    "    df.loc[missing_city, 'CITY'] = 'Chicago'\n",
    "    df.loc[missing_state, 'STATE'] = 'IL'\n",
    "    \n",
    "    print(\"\\nImputation abgeschlossen\")\n",
    "    print(f\"City gesetzt: {missing_city.sum()}, State gesetzt: {missing_state.sum()}\")\n",
    "    \n",
    "    imputed_rows = (to_reconstruct | missing_xy | missing_latlon | missing_location | missing_city | missing_state)\n",
    "    \n",
    "    # Rückgabe der betroffenen Zeilen\n",
    "    return df, df.loc[imputed_rows].index.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857e1fa",
   "metadata": {},
   "source": [
    "## 5. Ausführung der Funktionen und Erstellung neuer CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f39c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CODE 2: Koordinaten-Imputation gestartet\n",
      "\n",
      "\n",
      "Imputation abgeschlossen\n",
      "City gesetzt: 152238, State gesetzt: 152238\n",
      "Geocodiere 221 Adressen (ca. 4 Minuten)\n",
      "\n",
      "50/221 (22.6%) - Gefunden: 48\n",
      "100/221 (45.2%) - Gefunden: 96\n",
      "150/221 (67.9%) - Gefunden: 146\n",
      "200/221 (90.5%) - Gefunden: 196\n",
      "221/221 (100.0%) - Gefunden: 211\n",
      "\n",
      "Erfolgreich: 211/221 (95.5%)\n",
      "\n",
      "CODE 2: Koordinaten-Imputation gestartet\n",
      "\n",
      "\n",
      "Imputation abgeschlossen\n",
      "City gesetzt: 0, State gesetzt: 0\n",
      "\n",
      "--- Exporting CSVs ---\n",
      "'imputed_geo_data_only.csv': Enthält NUR die Zeilen, die neu imputiert wurden.\n",
      "all_data_with_imputed_geo.csv': Enthält ALLE Zeilen mit den finalen Geo-Daten.\n"
     ]
    }
   ],
   "source": [
    "# Sicherstellen, dass das Original erhalten bleibt \n",
    "df_imputed = df.copy()\n",
    "\n",
    "# Definierte Spalten für den finalen Export\n",
    "FINAL_GEO_COLS = [\n",
    "    'SR_NUMBER', 'STREET_ADDRESS', 'LATITUDE', 'LONGITUDE', \n",
    "    'X_COORDINATE', 'Y_COORDINATE', 'LOCATION', 'CITY', 'STATE',\n",
    "    'STREET_NUMBER', 'STREET_NAME', 'STREET_DIRECTION', 'STREET_TYPE'\n",
    "]\n",
    "\n",
    "# Filtere, um nur die wirklich vorhandenen Spalten zu verwenden\n",
    "available_final_cols = [c for c in FINAL_GEO_COLS if c in df_imputed.columns]\n",
    "\n",
    "# 1. Imputation\n",
    "df_imputed, imputed_idx = impute_coordinates(df_imputed)\n",
    "\n",
    "# 2. Geocoding (Extern) \n",
    "df_imputed, geocoded_idx = geocode_missing_addresses(df_imputed)\n",
    "\n",
    "# 3. Erneute Imputation nach neuen Lat/Lon \n",
    "df_imputed, imputed_idx2 = impute_coordinates(df_imputed)\n",
    "\n",
    "# Liste aller Indizes, die in irgendeinem Schritt bearbeitet wurden\n",
    "all_new_indices = sorted(set(imputed_idx) | set(geocoded_idx) | set(imputed_idx2))\n",
    "\n",
    "print(\"\\n--- Exporting CSVs ---\")\n",
    "\n",
    "# CSV NUR mit neu imputierten Zeilen und ALLEN Geo-Spalten\n",
    "# Hier verwenden wir die gefilterte Liste available_final_cols\n",
    "df_new_data = df_imputed.loc[all_new_indices, available_final_cols]\n",
    "df_new_data.to_csv(\"dataset/imputed_geo_data_only.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"'imputed_geo_data_only.csv': Enthält NUR die Zeilen, die neu imputiert wurden.\")\n",
    "\n",
    "\n",
    "# (2) CSV mit ALLEN Zeilen und ALLEN Geo-Spalten (neu und alt)\n",
    "df_all_data_geo_reduced = df_imputed[available_final_cols]\n",
    "df_all_data_geo_reduced.to_csv(\"dataset/all_data_with_imputed_geo.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"all_data_with_imputed_geo.csv': Enthält ALLE Zeilen mit den finalen Geo-Daten.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d7406",
   "metadata": {},
   "source": [
    "## 6. Erstellung einer CSV nur mit den neu gefundenen Koordinaten-Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0b160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exporting ONLY the 211 New Coordinates ---\n",
      "'dataset/only_211_new_coordinates.csv': Enthält 211 Zeilen, die erfolgreich neue Geo-Koordinaten erhalten haben (Erwartet: 211).\n",
      "\n",
      "--- Vorschau (Geo-Koordinaten) ---\n",
      "             SR_NUMBER       STREET_ADDRESS   LATITUDE  LONGITUDE\n",
      "358437   SR24-01894008       2159 W 92ND ST  41.726430 -87.675479\n",
      "1557117  SR24-00439859  2111 W Lexington ST  41.871914 -87.679850\n",
      "1557118  SR24-00439858  2111 W Lexington ST  41.871914 -87.679850\n",
      "1557267  SR24-00439695     10510 W ZEMKE RD  41.994980 -87.887581\n",
      "1557268  SR24-00439694     10510 W ZEMKE RD  41.994980 -87.887581\n"
     ]
    }
   ],
   "source": [
    "# 1. Filtern des DataFrames auf alle Zeilen, die an das externe Geocoding gesendet wurden (221 Adressen).\n",
    "# Die Variable 'geocoded_idx' wurde von 'geocode_missing_addresses' zurückgegeben.\n",
    "df_geocoding_attempts = df_imputed.loc[geocoded_idx].copy()\n",
    "\n",
    "# 2. Definiere, was Erfolg bedeutet: LATITUDE existiert und ist NICHT NaN.\n",
    "# Dies isoliert die Zeilen von den 221, bei denen der Prozess erfolgreich war.\n",
    "successfully_found_coords = df_geocoding_attempts['LATITUDE'].notna()\n",
    "\n",
    "# 3. Das finale DataFrame mit den 211 erfolgreich geocodierten Zeilen.\n",
    "df_211_coords = df_geocoding_attempts.loc[successfully_found_coords, available_final_cols]\n",
    "\n",
    "# 4. Export der CSV\n",
    "output_filename = \"dataset/only_211_new_coordinates.csv\"\n",
    "df_211_coords.to_csv(output_filename, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 5. Ausgabe zur Bestätigung\n",
    "print(\"\\n--- Exporting only the 211 New Coordinates ---\")\n",
    "print(f\"'{output_filename}': Enthält {len(df_211_coords)} Zeilen, die erfolgreich neue Geo-Koordinaten erhalten haben (Erwartet: 211).\")\n",
    "\n",
    "# Optional: Kurze Vorschau der ersten Zeilen\n",
    "print(\"\\n--- Vorschau (Geo-Koordinaten) ---\")\n",
    "print(df_211_coords[['SR_NUMBER', 'STREET_ADDRESS', 'LATITUDE', 'LONGITUDE']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97133f8",
   "metadata": {},
   "source": [
    "## 7. Untersuchung der Missing Values nach der Imputierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607dbb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after = pd.read_csv(\"dataset/all_data_with_imputed_geo.csv\") \n",
    "\n",
    "check_cols = [\n",
    "    'STREET_ADDRESS', 'LATITUDE', 'LONGITUDE', \n",
    "    'X_COORDINATE', 'Y_COORDINATE', 'LOCATION', 'CITY', 'STATE'\n",
    "]\n",
    "\n",
    "# Filtern der Spalten, die wirklich im DataFrame sind, um Fehler zu vermeiden\n",
    "available_check_cols = [c for c in check_cols if c in df_after.columns]\n",
    "\n",
    "missing_count = df_after[available_check_cols].isnull().sum()\n",
    "missing_percent = df_after[available_check_cols].isnull().mean() * 100\n",
    "\n",
    "missing_df_after = pd.DataFrame({\n",
    "    'Anzahl fehlender Werte': missing_count,\n",
    "    'Prozent fehlender Werte': missing_percent\n",
    "})\n",
    "\n",
    "# Sortieren und nur Zeilen mit fehlenden Werten anzeigen\n",
    "missing_df_after = missing_df_after[missing_df_after['Anzahl fehlender Werte'] > 0]\n",
    "missing_df_after = missing_df_after.sort_values(by='Anzahl fehlender Werte', ascending=False)\n",
    "\n",
    "print(\"Fehlende Werte NACH IM/GEOCODING (in den bearbeiteten Zeilen):\")\n",
    "print(missing_df_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a35dad",
   "metadata": {},
   "source": [
    "## 8. Weitere Untersuchung der Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce966e",
   "metadata": {},
   "source": [
    "### Wir suchen die 631 Zeilen, welche immer noch leer sind. (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stichprobe der 631 Zeilen, denen CITY/STATE fehlt ---\n",
      "Beachten Sie: STREET_ADDRESS, LATITUDE und WARD sollten alle fehlen (NaN), da die Imputationslogik diese Basisdaten benötigt.\n",
      "    SR_NUMBER STREET_ADDRESS  LATITUDE  WARD CITY STATE\n",
      "SR24-02337298            NaN       NaN   NaN  NaN   NaN\n",
      "SR24-02330082            NaN       NaN   NaN  NaN   NaN\n",
      "SR24-02327658            NaN       NaN   NaN  NaN   NaN\n",
      "SR24-02326382            NaN       NaN   NaN  NaN   NaN\n",
      "SR24-02315139            NaN       NaN   NaN  NaN   NaN\n",
      "SR24-02312297            NaN       NaN   NaN  NaN   NaN\n",
      "SR24-02312149            NaN       NaN   NaN  NaN   NaN\n",
      "SR24-02307862            NaN       NaN   NaN  NaN   NaN\n",
      "SR24-02289798            NaN       NaN   NaN  NaN   NaN\n",
      "SR24-02285656            NaN       NaN   NaN  NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "# 1. Filtern: Suche nach Zeilen, bei denen CITY ODER STATE fehlt (nach der Imputation in Zelle 6).\n",
    "# Basierend auf Ihrem Output: 631 Zeilen fehlen CITY und 631 Zeilen fehlen STATE.\n",
    "missing_city_state = df_imputed['CITY'].isna() | df_imputed['STATE'].isna()\n",
    "\n",
    "# 2. Filtern der relevanten Geo-Spalten (Basis für die Zuweisung)\n",
    "check_cols = ['SR_NUMBER', 'STREET_ADDRESS', 'LATITUDE', 'WARD', 'CITY', 'STATE']\n",
    "df_sample = df_imputed.loc[missing_city_state, check_cols]\n",
    "\n",
    "# 3. Ausgabe einer Stichprobe (z.B. die ersten 10 Zeilen)\n",
    "print(f\"\\n--- Stichprobe der {len(df_sample)} Zeilen, denen CITY/STATE fehlt ---\")\n",
    "print(\"Beachten Sie: STREET_ADDRESS, LATITUDE und WARD sollten alle fehlen (NaN), da die Imputationslogik diese Basisdaten benötigt.\")\n",
    "# to_string(index=False) anstelle von to_markdown()\n",
    "print(df_sample.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9dc14d",
   "metadata": {},
   "source": [
    "## 9. Bereinigung der neuen CSV Dateien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa4d7e",
   "metadata": {},
   "source": [
    "### Löschen aller Zeilen die noch NaN haben, die wir nicht imputieren konnten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240a338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Erfolgreich BEREINIGT und ÜBERSCHRIEBEN: 'dataset/imputed_geo_data_only.csv'\n",
      "   -> Überprüfte Spalten: ['LATITUDE', 'LONGITUDE', 'X_COORDINATE', 'Y_COORDINATE', 'LOCATION', 'CITY', 'STATE']\n",
      "   -> 100 Zeilen gelöscht (fehlende Daten in einer der Geo-Spalten).\n",
      "   -> Die Datei enthält jetzt 152344 Zeilen.\n",
      "\n",
      " Erfolgreich BEREINIGT und ÜBERSCHRIEBEN: 'dataset/all_data_with_imputed_geo.csv'\n",
      "   -> Überprüfte Spalten: ['LATITUDE', 'LONGITUDE', 'X_COORDINATE', 'Y_COORDINATE', 'LOCATION', 'CITY', 'STATE']\n",
      "   -> 804 Zeilen gelöscht (fehlende Daten in einer der Geo-Spalten).\n",
      "   -> Die Datei enthält jetzt 1913125 Zeilen.\n",
      "\n",
      " Erfolgreich BEREINIGT und ÜBERSCHRIEBEN: 'dataset/only_211_new_coordinates.csv'\n",
      "   -> Überprüfte Spalten: ['LATITUDE', 'LONGITUDE', 'X_COORDINATE', 'Y_COORDINATE', 'LOCATION', 'CITY', 'STATE']\n",
      "   -> 0 Zeilen gelöscht (fehlende Daten in einer der Geo-Spalten).\n",
      "   -> Die Datei enthält jetzt 211 Zeilen.\n",
      "\n",
      "--- Bereinigung abgeschlossen. Die Originaldateien wurden überschrieben. ---\n"
     ]
    }
   ],
   "source": [
    "# Liste der CSV-Dateien, die überschrieben werden sollen.\n",
    "csv_files_to_clean = [ \"dataset/imputed_geo_data_only.csv\", \"dataset/all_data_with_imputed_geo.csv\", \"dataset/only_211_new_coordinates.csv\" ]\n",
    "\n",
    "# Vollständige Liste der Geo-Spalten, die auf NaN geprüft werden sollen.\n",
    "geo_cols_to_check_all = [\n",
    "    'LATITUDE', \n",
    "    'LONGITUDE', \n",
    "    'X_COORDINATE', \n",
    "    'Y_COORDINATE', \n",
    "    'LOCATION', \n",
    "    'CITY',\n",
    "    'STATE',\n",
    "]\n",
    "\n",
    "for file_path in csv_files_to_clean:\n",
    "    \n",
    "    try:\n",
    "        # 1. Datei laden\n",
    "        df_csv = pd.read_csv(file_path)\n",
    "        initial_rows = len(df_csv)\n",
    "\n",
    "        # Filtere die Spalten, die tatsächlich in der aktuellen CSV-Datei existieren\n",
    "        available_geo_cols = [c for c in geo_cols_to_check_all if c in df_csv.columns]\n",
    "        \n",
    "        # 2. Lösche alle Zeilen, in denen in EINER der Geo-Spalten (available_geo_cols) ein NaN-Wert steht.\n",
    "        # 'how='any'' sorgt dafür, dass die Zeile bei der ersten gefundenen Lücke gelöscht wird.\n",
    "        df_cleaned_csv = df_csv.dropna(subset=available_geo_cols, how='any')\n",
    "        \n",
    "        final_rows = len(df_cleaned_csv)\n",
    "        rows_dropped = initial_rows - final_rows\n",
    "        \n",
    "        # 3. Bereinigte Daten UNTER DEM GLEICHEN NAMEN speichern (Überschreiben)\n",
    "        df_cleaned_csv.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "        \n",
    "        # 4. Ausgabe des Ergebnisses\n",
    "        print(f\"\\n Erfolgreich BEREINIGT und ÜBERSCHRIEBEN: '{file_path}'\")\n",
    "        print(f\"   -> Überprüfte Spalten: {available_geo_cols}\")\n",
    "        print(f\"   -> {rows_dropped} Zeilen gelöscht (fehlende Daten in einer der Geo-Spalten).\")\n",
    "        print(f\"   -> Die Datei enthält jetzt {final_rows} Zeilen.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nAchtung: Datei nicht gefunden: {file_path}. Überspringe.\")\n",
    "    except KeyError:\n",
    "        print(f\"\\nAchtung: Fehler beim Zugriff auf Spalten in {file_path}. Überspringe.\")\n",
    "\n",
    "print(\"Bereinigung abgeschlossen. Die Originaldateien wurden überschrieben.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a263d1ee",
   "metadata": {},
   "source": [
    "## 10. Überprüfen der restlichen Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c018c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte NACH IM/GEOCODING (in den bearbeiteten Zeilen):\n",
      "                Anzahl fehlender Werte  Prozent fehlender Werte\n",
      "STREET_ADDRESS                      12                 0.000627\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_after = pd.read_csv(\"dataset/all_data_with_imputed_geo.csv\") \n",
    "\n",
    "check_cols = [\n",
    "    'STREET_ADDRESS', 'LATITUDE', 'LONGITUDE', \n",
    "    'X_COORDINATE', 'Y_COORDINATE', 'LOCATION', 'CITY', 'STATE'\n",
    "]\n",
    "\n",
    "# Filtern der Spalten, die wirklich im DataFrame sind, um Fehler zu vermeiden\n",
    "available_check_cols = [c for c in check_cols if c in df_after.columns]\n",
    "\n",
    "missing_count = df_after[available_check_cols].isnull().sum()\n",
    "missing_percent = df_after[available_check_cols].isnull().mean() * 100\n",
    "\n",
    "missing_df_after = pd.DataFrame({\n",
    "    'Anzahl fehlender Werte': missing_count,\n",
    "    'Prozent fehlender Werte': missing_percent\n",
    "})\n",
    "\n",
    "# Sortieren und nur Zeilen mit fehlenden Werten anzeigen\n",
    "missing_df_after = missing_df_after[missing_df_after['Anzahl fehlender Werte'] > 0]\n",
    "missing_df_after = missing_df_after.sort_values(by='Anzahl fehlender Werte', ascending=False)\n",
    "\n",
    "print(\"Fehlende Werte NACH IM/GEOCODING (in den bearbeiteten Zeilen):\")\n",
    "print(missing_df_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970e723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 12 Zeilen mit fehlender STREET_ADDRESS (NaN) ---\n",
      "    SR_NUMBER STREET_ADDRESS STREET_NUMBER STREET_NAME STREET_DIRECTION STREET_TYPE  LATITUDE  LONGITUDE    CITY\n",
      "SR24-02333234            NaN           NaN         NaN              NaN         NaN 41.994271 -87.679933 Chicago\n",
      "SR24-01986028            NaN           NaN         NaN              NaN         NaN 41.827544 -87.611632 Chicago\n",
      "SR24-01681103            NaN           NaN         NaN              NaN         NaN 41.994271 -87.679933 Chicago\n",
      "SR24-01389933            NaN           NaN         NaN              NaN         NaN 41.913638 -87.710186 Chicago\n",
      "SR24-01378822            NaN           NaN         NaN              NaN         NaN 41.994271 -87.679933 Chicago\n",
      "SR24-01377294            NaN           NaN         NaN              NaN         NaN 41.913638 -87.710186 Chicago\n",
      "SR24-01205862            NaN           NaN         NaN              NaN         NaN 41.895062 -87.650132 Chicago\n",
      "SR24-01170340            NaN           NaN         NaN              NaN         NaN 41.895062 -87.650132 Chicago\n",
      "SR24-01025325            NaN           NaN         NaN              NaN         NaN 41.895062 -87.650132 Chicago\n",
      "SR24-00924222            NaN           NaN         NaN              NaN         NaN 41.895062 -87.650132 Chicago\n",
      "SR24-00843094            NaN           NaN         NaN              NaN         NaN 41.938510 -87.690113 Chicago\n",
      "SR24-00239411            NaN           NaN         NaN              NaN         NaN 41.994271 -87.679933 Chicago\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CSV_FILE = \"dataset/all_data_with_imputed_geo.csv\"\n",
    "try:\n",
    "    # 1. CSV-Datei laden\n",
    "    df_csv = pd.read_csv(CSV_FILE)\n",
    "    \n",
    "    # 2. Filtern nach Zeilen, bei denen die STREET_ADDRESS fehlt (NaN ist)\n",
    "    missing_address_mask = df_csv['STREET_ADDRESS'].isna()\n",
    "    \n",
    "    # 3. Auswahl relevanter Spalten zur Überprüfung\n",
    "    check_cols = [\n",
    "        'SR_NUMBER', 'STREET_ADDRESS', 'STREET_NUMBER', \n",
    "        'STREET_NAME', 'STREET_DIRECTION', 'STREET_TYPE', \n",
    "        'LATITUDE', 'LONGITUDE', 'CITY'\n",
    "    ]\n",
    "    \n",
    "    # Filtere, um nur die Spalten zu verwenden, die wirklich in der CSV existieren\n",
    "    available_check_cols = [c for c in check_cols if c in df_csv.columns]\n",
    "    \n",
    "    df_missing_address = df_csv.loc[missing_address_mask, available_check_cols]\n",
    "    \n",
    "    # 4. Ausgabe des Ergebnisses\n",
    "    anzahl_fehlend = len(df_missing_address)\n",
    "    print(f\"\\n--- {anzahl_fehlend} Zeilen mit fehlender STREET_ADDRESS (NaN) ---\")\n",
    "    \n",
    "    if anzahl_fehlend > 0:\n",
    "        # Zeige die ersten 50 Zeilen (oder alle 12 Zeilen, wenn die Anzahl stimmt)\n",
    "        print(df_missing_address.head(50).to_string(index=False))\n",
    "    else:\n",
    "        print(\"Keine Zeilen mit fehlender STREET_ADDRESS in dieser CSV gefunden.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nFEHLER: Die Datei {CSV_FILE} wurde nicht gefunden. Stellen Sie sicher, dass der Pfad korrekt ist und die Datei existiert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb60bc6",
   "metadata": {},
   "source": [
    "## 11. Mithilfe von Geocoding Adressen befüllen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ba4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeite 12 Adressen via Reverse Geocoding...\n",
      "Reverse Geocoding abgeschlossen. 12 Adressen erfolgreich imputiert.\n",
      "Verbleibende fehlende Adressen nach diesem Schritt: 0\n"
     ]
    }
   ],
   "source": [
    "CSV_FILE_TO_UPDATE = \"dataset/all_data_with_imputed_geo.csv\"\n",
    "geolocator = Nominatim(user_agent=\"chicago_311_csv_update\") \n",
    "\n",
    "def reverse_geocode_csv(file_path):\n",
    "    \n",
    "    try:\n",
    "        # 1. Datei laden\n",
    "        df_update = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FEHLER: Datei {file_path} nicht gefunden. Abbruch.\")\n",
    "        return\n",
    "\n",
    "    # 2. Filtern: Suche nach Zeilen, die LAT/LON haben, aber keine STREET_ADDRESS\n",
    "    to_reverse_geocode = (df_update['STREET_ADDRESS'].isna()) & \\\n",
    "                         (df_update['LATITUDE'].notna()) & \\\n",
    "                         (df_update['LONGITUDE'].notna())\n",
    "    \n",
    "    count_to_process = to_reverse_geocode.sum()\n",
    "    if count_to_process == 0:\n",
    "        print(\"Keine Zeilen für Reverse Geocoding in dieser CSV gefunden. Keine Änderung vorgenommen.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Verarbeite {count_to_process} Adressen via Reverse Geocoding...\")\n",
    "    \n",
    "    imputed_count = 0\n",
    "\n",
    "    # 3. Iteration nur über die betroffenen Zeilen im temporären DataFrame\n",
    "    for idx in df_update[to_reverse_geocode].index:\n",
    "        lat = df_update.loc[idx, 'LATITUDE']\n",
    "        lon = df_update.loc[idx, 'LONGITUDE']\n",
    "        \n",
    "        try:\n",
    "            location = geolocator.reverse((lat, lon), timeout=15) \n",
    "            \n",
    "            if location and location.address:\n",
    "                df_update.loc[idx, 'STREET_ADDRESS'] = location.address\n",
    "                \n",
    "                # Versuche, Komponenten zu extrahieren (falls vorhanden)\n",
    "                address_details = location.raw.get('address', {})\n",
    "                df_update.loc[idx, 'STREET_NUMBER'] = address_details.get('house_number', pd.NA)\n",
    "                df_update.loc[idx, 'STREET_NAME'] = address_details.get('road', pd.NA)\n",
    "                \n",
    "                imputed_count += 1\n",
    "                \n",
    "        except Exception:\n",
    "            # Bei Fehlern die Zeile überspringen\n",
    "            pass\n",
    "\n",
    "        # Warte 1 Sekunde zur Vermeidung von Rate Limiting\n",
    "        time.sleep(1) \n",
    "        \n",
    "    print(f\"Reverse Geocoding abgeschlossen. {imputed_count} Adressen erfolgreich imputiert.\")\n",
    "\n",
    "    # 4. CSV-Datei überschreiben\n",
    "    df_update.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Verbleibende fehlende Adressen nach diesem Schritt: {df_update['STREET_ADDRESS'].isna().sum()}\")\n",
    "\n",
    "reverse_geocode_csv(CSV_FILE_TO_UPDATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "087404c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dataset/imputed_geo_data_only.csv': Gesamt fehlende Geo-Werte (NaN): 0\n",
      "'dataset/all_data_with_imputed_geo.csv': Gesamt fehlende Geo-Werte (NaN): 0\n",
      "'dataset/only_211_new_coordinates.csv': Gesamt fehlende Geo-Werte (NaN): 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = [\"dataset/imputed_geo_data_only.csv\", \"dataset/all_data_with_imputed_geo.csv\", \"dataset/only_211_new_coordinates.csv\"]\n",
    "geo_cols = ['LATITUDE', 'LONGITUDE', 'X_COORDINATE', 'Y_COORDINATE', 'LOCATION', 'STATE', 'CITY']\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    available_cols = [c for c in geo_cols if c in df.columns]\n",
    "    total_nan = df.loc[:, available_cols].isna().sum().sum()\n",
    "    print(f\"'{file}': Gesamt fehlende Geo-Werte (NaN): {total_nan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec7679",
   "metadata": {},
   "source": [
    "Jetzt haben wir die drei CSV Files komplett imputiert mithilfe von\n",
    "\n",
    "- Neovatim: Street Address Latitude und Longitude hinzugefügt und Reverse\n",
    "\n",
    "- Transformer: wenn Teile vergessen wurden, aber schon in anderen (mathematisch gleichen) Spalten standen wurden sie in die anderen rübergefügt( Beispiel X und Y Koordinaten und Latitude und Longitude z B so: transformiert von EPSG:4326 (LAT/LONG) zu EPSG:3435 (X/Y))\n",
    "\n",
    "- und zum Schluss löschen der NaN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
